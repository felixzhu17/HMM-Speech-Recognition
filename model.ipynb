{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa\n",
    "from IPython.display import Audio\n",
    "from batch_hmm import *\n",
    "from dnn_hmm import *\n",
    "from mfcc import *\n",
    "from hmm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "\n",
    "# Number of hidden states\n",
    "n_components = 2\n",
    "\n",
    "# Dimensionality of the observations\n",
    "n_features = 3\n",
    "\n",
    "# Create a Gaussian HMM\n",
    "model = hmm.GaussianHMM(\n",
    "    n_components=n_components, \n",
    "    covariance_type=\"diag\"\n",
    ")\n",
    "\n",
    "# Manually specify the model parameters\n",
    "model.startprob_ = np.array([1, 0])\n",
    "\n",
    "model.transmat_ = np.array([\n",
    "    [0.7, 0.3],\n",
    "    [0.4, 0.6],\n",
    "])\n",
    "\n",
    "# Means of each hidden state\n",
    "model.means_ = np.array([\n",
    "    [0.0, 0.0, 0.0], \n",
    "    [5.0, 5.0, 5.0]\n",
    "])\n",
    "\n",
    "# Covariances of each hidden state\n",
    "model.covars_ = np.ones((n_components, n_features))\n",
    "\n",
    "# Generate samples\n",
    "X = np.stack([model.sample(100)[0] for _ in range(100)])\n",
    "\n",
    "print(\"Shape of X:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = BatchStableGMMHMM(n_states = 2, n_dims = 3)\n",
    "self.mu = np.array([[1, 2, 0], [6, 8, 10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(25):\n",
    "    self.em_step(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 8000\n",
    "N_STATES = 5\n",
    "N_DIMENSIONS = 12\n",
    "N_ENCODING = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Encoder(input_dim = N_DIMENSIONS, output_dim = len(spoken), encoding_dim = N_ENCODING, n_heads = 4, dropout = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders for train and test set\n",
    "train_data = DataLoader(WordDataset(x_train, y_train, mask_train), batch_size=32, shuffle=True)\n",
    "test_data = DataLoader(WordDataset(x_test, y_test, mask_test), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "    for x, y, mask in train_data:\n",
    "        optimizer.zero_grad()  # zero the parameter gradients\n",
    "        \n",
    "        outputs = model(x, mask)  # forward pass, get the output of the network\n",
    "        \n",
    "        loss = criterion(outputs, y)  # calculate the loss\n",
    "        loss.backward()  # backward pass, compute gradient of the loss with respect to model parameters\n",
    "        optimizer.step()  # update model parameters\n",
    "        \n",
    "        #print(f'Epoch: {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 Accuracy:  1.0\n",
      "Top 3 Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "def top1_accuracy(output, target):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        pred = torch.argmax(output, 1)\n",
    "        correct = pred.eq(target.view_as(pred))\n",
    "        correct = correct.float().sum()\n",
    "        return correct / len(target)\n",
    "\n",
    "\n",
    "def topk_accuracy(output, target, k=3):\n",
    "    \"\"\"Computes the topk accuracy\"\"\"\n",
    "    with torch.no_grad():\n",
    "        pred = torch.topk(output, k, dim=1)[1]\n",
    "        correct = pred.eq(target.view(-1, 1).expand_as(pred))\n",
    "        correct_k = correct.view(-1).float().sum()\n",
    "        return correct_k / len(target)\n",
    "\n",
    "\n",
    "# Let's say our model is called `model`\n",
    "# and make sure it is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "top1_acc = 0\n",
    "top3_acc = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, targets, masks) in enumerate(test_data):\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        top1_acc += top1_accuracy(outputs, targets) * len(targets)\n",
    "        top3_acc += topk_accuracy(outputs, targets) * len(targets)\n",
    "        total_samples += len(targets)\n",
    "\n",
    "# Calculate the average accuracies\n",
    "top1_acc = top1_acc / total_samples\n",
    "top3_acc = top3_acc / total_samples\n",
    "\n",
    "print(\"Top 1 Accuracy: \", top1_acc.item())\n",
    "print(\"Top 3 Accuracy: \", top3_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_models = {}\n",
    "for word in spoken:\n",
    "    dnn_models[word] = BatchStableGMMHMM(N_STATES, N_DIMENSIONS)\n",
    "    for _ in range(1):\n",
    "        dnn_models[word].em_step(data[word][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gmm_models = {}\n",
    "# for word in spoken:\n",
    "#     gmm_models[word] = BatchStableGMMHMM(N_STATES, N_DIMENSIONS)\n",
    "#     for _ in range(50):\n",
    "#         gmm_models[word].em_step(data[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(models):\n",
    "    # Initialize counters for top 1 and top 3 predictions\n",
    "    top1_count = 0\n",
    "    top3_count = 0\n",
    "\n",
    "    # Total number of items\n",
    "    total_count = len(raw_data)\n",
    "\n",
    "    # Iterate over all elements in raw_data\n",
    "    for index in range(total_count):\n",
    "        test_data = raw_data[index]\n",
    "        true_label = test_data['label']\n",
    "        obs = test_data['mfcc'][np.newaxis, :]\n",
    "        prediction = {k:v.log_likelihood(obs) for k,v in models.items()}\n",
    "\n",
    "        # Sort predictions in descending order\n",
    "        sorted_predictions = sorted(prediction.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Check if true_label is the top prediction\n",
    "        is_top1 = true_label == sorted_predictions[0][0]\n",
    "        if is_top1:\n",
    "            top1_count += 1  # Increase counter if true_label is the top prediction\n",
    "\n",
    "        # Check if true_label is in the top three predictions\n",
    "        is_top3 = true_label in [item[0] for item in sorted_predictions[:3]]\n",
    "        if is_top3:\n",
    "            top3_count += 1  # Increase counter if true_label is in the top three predictions\n",
    "\n",
    "    # Calculate percentages\n",
    "    top1_percentage = (top1_count / total_count) * 100\n",
    "    top3_percentage = (top3_count / total_count) * 100\n",
    "\n",
    "    print(\"Top 1 prediction accuracy: \", top1_percentage, \"%\")\n",
    "    print(\"Top 3 prediction accuracy: \", top3_percentage, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_model(dnn_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a time array for the x-axis\n",
    "# t = np.arange(len(y)) / sr\n",
    "\n",
    "# # Create a plot\n",
    "# plt.figure(figsize=(14, 5))\n",
    "# plt.plot(t, y)\n",
    "# plt.title('Time-Amplitude plot')\n",
    "# plt.xlabel('Time (s)')\n",
    "# plt.ylabel('Amplitude')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # STFT calculation\n",
    "# stft_result = stft(y)\n",
    "\n",
    "# # Time-Frequency plot\n",
    "# plt.figure(figsize=(14, 5))\n",
    "# librosa.display.specshow(librosa.amplitude_to_db(stft_result.T), sr=sr, x_axis='time', y_axis='log')\n",
    "# plt.colorbar(format='%+2.0f dB')\n",
    "# plt.title('Time-Frequency plot')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate MFCCs\n",
    "# mfccs = get_mfcc(y, sr)\n",
    "\n",
    "# # Plot the MFCCs\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# plt.imshow(mfccs.T, origin='lower', aspect='auto', cmap='viridis')\n",
    "# plt.title('MFCC')\n",
    "# plt.ylabel('MFCC Coefficients')\n",
    "# plt.xlabel('Frame')\n",
    "# plt.colorbar()\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('test_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4cf0c84cb920ef818a17945acdbad69d9a4ddd40487682b0650d6bc1faebf3dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
